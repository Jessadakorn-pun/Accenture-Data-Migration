{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78f2e9eb",
   "metadata": {},
   "source": [
    "# Reconcile PA-0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c287d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba28ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using for convert string to sortable date format and back\n",
    "def to_sortable(date_str: str) -> str:\n",
    "    if pd.isna(date_str):\n",
    "        return np.nan\n",
    "    # date_str is \"DD.MM.YYYY\"\n",
    "    else:\n",
    "        dd, mm, yyyy = date_str.split('.')\n",
    "        return f\"{yyyy}{mm}{dd}\"      # \"YYYYMMDD\"\n",
    "\n",
    "def to_original(code: str) -> str:\n",
    "    if pd.isna(code):\n",
    "        return np.nan\n",
    "    else:\n",
    "        # code is \"YYYYMMDD\"\n",
    "        yyyy, mm, dd = code[:4], code[4:6], code[6:8]\n",
    "        return f\"{dd}.{mm}.{yyyy}\"    # \"DD.MM.YYYY\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a25ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define file paths for different data files\n",
    "## เปลี่ยนตรงนี้\n",
    "path_PA_0000 = r\"C:\\Users\\wasurat.boonnan\\OneDrive - Accenture\\Desktop\\Data Trnasfomation\\Transformed Data\\Mock4 Cut Over\\M4 Reconcile\\0000-0001\\PostLoad_PA-0000.txt\"\n",
    "path_PA_0001 = r\"C:\\Users\\wasurat.boonnan\\OneDrive - Accenture\\Desktop\\Data Trnasfomation\\Transformed Data\\Mock4 Cut Over\\M4 Reconcile\\0000-0001\\PostLoad_PA-0001.txt\"\n",
    "path_PA_0302 = r\"C:\\Users\\wasurat.boonnan\\OneDrive - Accenture\\Desktop\\Data Trnasfomation\\Transformed Data\\Mock4 Cut Over\\M4 Reconcile\\0000-0001\\PostLoad_PA-0302.txt\"\n",
    "path_HRP_1001_SP = r\"C:\\Users\\wasurat.boonnan\\OneDrive - Accenture\\Desktop\\Data Trnasfomation\\Transformed Data\\Mock4 Cut Over\\M4 Reconcile\\0000-0001\\PostLoad_HRP-1001-SP.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6d45e6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Prep PA-0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8dbf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data files\n",
    "df_PA_0000 = pd.read_csv(path_PA_0000, sep=\"\\t\", encoding=\"utf-8\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c98789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the columns to select\n",
    "col_PA_0000 = [\"PERNR\" ,\"BEGDA\" ,\"ENDDA\" ,\"SEQNR\" ,\"MASSN\" ,\"MASSG\" ,\"STAT2\"]\n",
    "\n",
    "# clean up column names by stripping whitespace\n",
    "df_PA_0000.columns = df_PA_0000.columns.str.strip()\n",
    "\n",
    "print(df_PA_0000.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de03303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the relevant columns\n",
    "df_PA_0000 = df_PA_0000[col_PA_0000]\n",
    "\n",
    "# convert PERNR to string, strip whitespace, and pad with zeros\n",
    "df_PA_0000['PERNR'] = df_PA_0000['PERNR'].str.strip()\n",
    "df_PA_0000['PERNR'] = df_PA_0000['PERNR'].astype(str).str.zfill(8)\n",
    "df_PA_0000 = df_PA_0000.add_prefix(\"0000_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72c6261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the DataFrame\n",
    "df_PA_0000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d19d78",
   "metadata": {},
   "source": [
    "# Prep PA-0302"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e35456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data files\n",
    "df_PA_0302 = pd.read_csv(path_PA_0302, sep=\"\\t\", encoding=\"utf-8\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db70afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the columns to select for PA-0302\n",
    "col_PA_0302 = [\"PERNR\" ,\"BEGDA\" ,\"ENDDA\" ,\"SEQNR\" ,\"MASSN\" ,\"MASSG\"]\n",
    "\n",
    "# clean up column names by stripping whitespace\n",
    "df_PA_0302.columns = df_PA_0302.columns.str.strip()\n",
    "print(df_PA_0302.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5a3c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the relevant columns\n",
    "df_PA_0302 = df_PA_0302[col_PA_0302]\n",
    "\n",
    "# convert PERNR to string, strip whitespace, and pad with zeros\n",
    "df_PA_0302['PERNR'] = df_PA_0302['PERNR'].str.strip()\n",
    "df_PA_0302['PERNR'] = df_PA_0302['PERNR'].astype(str).str.zfill(8)\n",
    "df_PA_0302 = df_PA_0302.add_prefix(\"0302_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0797665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the DataFrame\n",
    "df_PA_0302"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78093b1",
   "metadata": {},
   "source": [
    "# Prep PA-0001\n",
    "Prepare Logic\n",
    "- HRP1001-SP join PA0001 (on \"PERNER\" \"OBJID\" / \"PERNER\" \"PLANS\" (add index before left join)) \n",
    "- select HRP1001-SP record if \"BEGDA\" and \"ENDDA\" of PA0001 in range PA0001 เเต่ record ที่ join ไม่เจอต้องเอามาด้วย"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a376a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data files\n",
    "df_PA_0001 = pd.read_csv(path_PA_0001, sep=\"\\t\", encoding=\"utf-8\", dtype=str)\n",
    "df_HRP_1001_SP = pd.read_csv(path_HRP_1001_SP, sep=\"\\t\", encoding=\"utf-8\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f0e5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the columns to select for PA-0302\n",
    "col_PA_0001 = [\n",
    "                \"PERNR\", \"BEGDA\", \"ENDDA\", \"BUKRS\", \"WERKS\", \n",
    "                \"BTRTL\", \"KOSTL\", \"GSBER\", \"PERSG\", \"ABKRS\",\n",
    "                \"PERSK\", \"ANSVH\", \"PLANS\", \"STELL\",\n",
    "                \"ORGEH\", \"SBMOD\", \"SACHP\", \"SACHZ\", \"SACHA\", \"MSTBR\"\n",
    "            ]\n",
    "\n",
    "# clean up column names by stripping whitespace\n",
    "df_PA_0001.columns = df_PA_0001.columns.str.strip()\n",
    "print(df_PA_0001.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1c974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the columns to select for PA-0302\n",
    "col_HRP_1001_SP = [\n",
    "        'OTYPE', 'OBJID', 'BEGDA', 'ENDDA', 'SOBID', 'PROZT'\n",
    "       ]\n",
    "\n",
    "# clean up column names by stripping whitespace\n",
    "df_HRP_1001_SP.columns = df_HRP_1001_SP.columns.str.strip()\n",
    "print(df_HRP_1001_SP.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba239ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HRP_1001_SP = df_HRP_1001_SP[col_HRP_1001_SP]\n",
    "df_HRP_1001_SP = df_HRP_1001_SP.add_prefix(\"1001_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af13001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HRP_1001_SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134fd702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the relevant columns\n",
    "df_PA_0001 = df_PA_0001[col_PA_0001]\n",
    "# reset the index of df_PA_0001\n",
    "df_PA_0001.reset_index(inplace=True) \n",
    "# increment the index by 1\n",
    "df_PA_0001['index'] = df_PA_0001['index'] + 1\n",
    "\n",
    "# ensure it's string, then zfill to width 8\n",
    "df_PA_0001[\"PERNR\"] = df_PA_0001[\"PERNR\"].str.strip()\n",
    "df_PA_0001[\"PERNR\"] = df_PA_0001[\"PERNR\"].astype(str).str.zfill(8)\n",
    "df_PA_0001 = df_PA_0001.add_prefix(\"0001_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7b6e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PA_0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34494720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join df_PA_0001 with df_HRP_1001_SP on PERNR and PLANS\n",
    "# using inner join to find matching records\n",
    "df_PA_0001_leftMerge = df_PA_0001.merge(\n",
    "    df_HRP_1001_SP, \n",
    "    left_on=['0001_PERNR', '0001_PLANS'], \n",
    "    right_on=['1001_SOBID', '1001_OBJID'],\n",
    "    # how='inner'\n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add7a593",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_PA_0001))\n",
    "print(len(df_HRP_1001_SP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894bfcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PA_0001_leftMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e8473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date columns to sortable format\n",
    "df_PA_0001_leftMerge['0001_SORT_BEGDA'] = df_PA_0001_leftMerge['0001_BEGDA'].apply(to_sortable)\n",
    "df_PA_0001_leftMerge['0001_SORT_ENDDA'] = df_PA_0001_leftMerge['0001_ENDDA'].apply(to_sortable)\n",
    "df_PA_0001_leftMerge['1001_SORT_BEGDA'] = df_PA_0001_leftMerge['1001_BEGDA'].apply(to_sortable)\n",
    "df_PA_0001_leftMerge['1001_SORT_ENDDA'] = df_PA_0001_leftMerge['1001_ENDDA'].apply(to_sortable)\n",
    "\n",
    "# create filter mask for overlapping date ranges of PA-0001 and HRP-1001-SP\n",
    "mask = (\n",
    "    (df_PA_0001_leftMerge['1001_SORT_BEGDA'].isna() &  df_PA_0001_leftMerge['1001_SORT_ENDDA'].isna() ) | # including null records\n",
    "    (df_PA_0001_leftMerge['0001_SORT_ENDDA'] >= df_PA_0001_leftMerge['1001_SORT_BEGDA']) &\n",
    "    (df_PA_0001_leftMerge['0001_SORT_BEGDA'] <= df_PA_0001_leftMerge['1001_SORT_ENDDA'])\n",
    ")\n",
    "    \n",
    "# apply the mask to filter the DataFrame\n",
    "df_PA_0001_leftMerge_filtered = df_PA_0001_leftMerge[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837d992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = df_PA_0001_leftMerge[~mask]\n",
    "check[['0001_index', '0001_PERNR', \"0001_BEGDA\", \"0001_ENDDA\", \"1001_BEGDA\", \"1001_ENDDA\", \"1001_PROZT\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bda7c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before filtering\n",
    "df_PA_0001_leftMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2b7a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after filtering\n",
    "df_PA_0001_leftMerge_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fdaa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_number over(partition by index order by PROZT)\n",
    "df_PA_0001_find_prozt = df_PA_0001_leftMerge_filtered.copy()\n",
    "df_PA_0001_find_prozt = df_PA_0001_find_prozt[['0001_index', '0001_PERNR', '0001_BEGDA', '0001_ENDDA', '1001_PROZT']]\n",
    "df_PA_0001_find_prozt = df_PA_0001_find_prozt.sort_values(['0001_index','1001_PROZT'])\n",
    "\n",
    "df_PA_0001_find_prozt['row_number'] = df_PA_0001_find_prozt.groupby('0001_index').cumcount() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46c3117",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PA_0001_find_prozt = df_PA_0001_find_prozt[df_PA_0001_find_prozt['row_number'] == 1]\n",
    "df_PA_0001_find_prozt = df_PA_0001_find_prozt.add_prefix(\"findProzt_\")\n",
    "df_PA_0001_find_prozt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea1dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join df_PA_0001 with df_HRP_1001_SP on PERNR and PLANS\n",
    "# using inner join to find matching records\n",
    "df_PA_0001_final = df_PA_0001.merge(\n",
    "    df_PA_0001_find_prozt, \n",
    "    left_on=['0001_index'], \n",
    "    right_on=['findProzt_0001_index'],\n",
    "    # how='inner'\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_PA_0001_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaacf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_PA_0001_merge = [\n",
    "    \"0001_PERNR\", \"0001_BEGDA\", \"0001_ENDDA\", \"0001_BUKRS\", \"0001_WERKS\", \"0001_BTRTL\", \"0001_KOSTL\", \"0001_GSBER\", \n",
    "    \"0001_PERSG\", \"0001_ABKRS\", \"0001_PERSK\", \"0001_ANSVH\", \"findProzt_1001_PROZT\", \"0001_PLANS\", \"0001_STELL\", \"0001_ORGEH\", \n",
    "    \"0001_SBMOD\", \"0001_SACHP\", \"0001_SACHZ\", \"0001_SACHA\", \"0001_MSTBR\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04221777",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PA_0001_final = df_PA_0001_final[col_PA_0001_merge].copy()\n",
    "df_PA_0001_final.rename(columns={\n",
    "    # 'PERNR_x': 'PERNR',\n",
    "    # 'BEGDA_x': 'BEGDA',\n",
    "    'findProzt_1001_PROZT': '1001_PROZT'\n",
    "}, inplace=True)\n",
    "\n",
    "## New Adding\n",
    "# fill NA with 0 in columns : STELL ORGEH\n",
    "df_PA_0001_final['0001_STELL'].fillna(\"00000000\", inplace=True)\n",
    "df_PA_0001_final['0001_ORGEH'].fillna(\"00000000\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336587b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_PA_0001_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b547bb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PA_0001_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e4845a",
   "metadata": {},
   "source": [
    "# Consolidate the data for PA-0000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2dd7d2",
   "metadata": {},
   "source": [
    "- PA0302 join PA0000 (PERNER, BEGDA) -> PA0000:ENDDA STAT2\n",
    "- ROW_NUMBER OVER(partition by PERNER, BEGDA)\n",
    "- JOIN 0001\n",
    "- FILL DOWN 0001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d580db11",
   "metadata": {},
   "source": [
    "## Post Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4e393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge df_PA_0000 and df_PA_0302 on PERNR and BEGDA\n",
    "result_1 = df_PA_0302.merge(\n",
    "    df_PA_0000, \n",
    "    left_on=['0302_PERNR', '0302_BEGDA'], \n",
    "    right_on=['0000_PERNR', '0000_BEGDA'],\n",
    "    how='inner'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee98d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the result\n",
    "df_PA_0302[(df_PA_0302['0302_PERNR'] == '00160044') & (df_PA_0302['0302_BEGDA'] == '01.10.2005')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f55b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the result\n",
    "df_PA_0000[(df_PA_0000['0000_PERNR'] == '00160044') & (df_PA_0000['0000_BEGDA'] == '01.10.2005')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eb046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the result\n",
    "result_1[(result_1['0302_PERNR'] == '00160044') & (result_1['0302_BEGDA'] == '01.10.2005')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff42d961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the relevant columns from result_1\n",
    "result_1_col = [\n",
    "    \"0302_PERNR\", \"0302_BEGDA\", \"0000_ENDDA\", \"0302_SEQNR\", \"0302_MASSN\", \"0302_MASSG\", \"0000_STAT2\"\n",
    "]\n",
    "\n",
    "# select the relevant columns from result_1\n",
    "result_2 = result_1[result_1_col].copy()\n",
    "\n",
    "# adding row number for each PERNR and BEGDA\n",
    "result_2['ROW_NUMBER'] = result_2.groupby(['0302_PERNR', '0302_BEGDA']).cumcount() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28b25e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the result\n",
    "result_2[(result_2['0302_PERNR'] == '00160044') & (result_2['0302_BEGDA'] == '01.10.2005')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b5838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PA_0001_final[df_PA_0001_final['0001_PERNR'] == '00400036']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c798bb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tables with prefixes for merging\n",
    "pa0000_table = result_2.add_prefix('0_')\n",
    "pa0001_table = df_PA_0001_final.add_prefix('1_')\n",
    "\n",
    "# fill pa0302 sequence NA with 0\n",
    "pa0000_table['0_0302_SEQNR'] = pa0000_table['0_0302_SEQNR'].fillna(0)\n",
    "\n",
    "# merge the pa0000 and pa0001 tables on PERNR and BEGDA\n",
    "consolidate = pd.merge(\n",
    "                    pa0000_table, pa0001_table, \n",
    "                    left_on=['0_0302_PERNR', '0_0302_BEGDA'],\n",
    "                    right_on=['1_0001_PERNR', '1_0001_BEGDA'],\n",
    "                    how='outer'\n",
    ")\n",
    "\n",
    "# create pernr column using for sort\n",
    "consolidate['PERNR'] = np.where(\n",
    "    consolidate['1_0001_PERNR'].isna() | (consolidate['1_0001_PERNR'] == ''),\n",
    "    consolidate['0_0302_PERNR'],\n",
    "    consolidate['1_0001_PERNR']\n",
    ")\n",
    "\n",
    "consolidate['BEGDA'] = np.where(\n",
    "    consolidate['1_0001_BEGDA'].isna() | (consolidate['1_0001_BEGDA'] == ''),\n",
    "    consolidate['0_0302_BEGDA'],\n",
    "    consolidate['1_0001_BEGDA']\n",
    ")\n",
    "\n",
    "# convert BEGDA to sortable format for sorting\n",
    "consolidate['BEGDA_SORT'] = consolidate['BEGDA'].apply(to_sortable)\n",
    "\n",
    "# sort the consolidated DataFrame by PERNR and BEGDA_SORT\n",
    "consolidate.sort_values(by=['PERNR', 'BEGDA_SORT', '0_0302_SEQNR'], inplace=True)\n",
    "\n",
    "# adding sequence number\n",
    "consolidate['SEQUENCE'] = consolidate['0_0302_SEQNR'].fillna(0)\n",
    "\n",
    "# define columns to fill down\n",
    "cols_to_fill = [c for c in consolidate.columns if c not in ['PERNR', 'BEGDA', 'BEGDA_SORT', '0_0302_SEQNR','SEQUENCE']]\n",
    "\n",
    "# group by PERNR and fill down the values in the specified columns\n",
    "consolidate_filled = consolidate.copy()\n",
    "\n",
    "consolidate_filled[cols_to_fill] = (\n",
    "    consolidate_filled\n",
    "    .groupby(['PERNR'])[cols_to_fill]\n",
    "    .transform(lambda g: g.ffill())\n",
    ")\n",
    "\n",
    "# reset the index of the filled DataFrame\n",
    "consolidate_filled.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db715030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before filling down\n",
    "len(consolidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4f4753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after filling down\n",
    "len(consolidate_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716f6736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy final DataFrame for postload\n",
    "postload = consolidate_filled.copy()\n",
    "# drop unnecessary columns\n",
    "postload = postload.drop(columns=['PERNR', 'BEGDA', 'BEGDA_SORT', '0_ROW_NUMBER', 'SEQUENCE'])\n",
    "\n",
    "# rename columns to match preload format\n",
    "org_col = postload.columns.str.replace(r'\\d{4}_', '', regex=True)\n",
    "\n",
    "postload.columns = org_col\n",
    "\n",
    "postload = postload.add_prefix('postload_')\n",
    "\n",
    "# strip whitespace from all object columns\n",
    "postload = postload.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dd0322",
   "metadata": {},
   "outputs": [],
   "source": [
    "postload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8b75f3",
   "metadata": {},
   "source": [
    "## Preload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f83468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define preload path\n",
    "## เปลี่ยนตรงนี้\n",
    "path_preload = r\"C:\\Users\\wasurat.boonnan\\OneDrive - Accenture\\Desktop\\Data Trnasfomation\\Transformed Data\\Mock4 Cut Over\\M4 Reconcile\\0000-0001\\Preload_PA-0000.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d32b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data files\n",
    "preload_org = pd.read_csv(path_preload, sep=\"\\t\", encoding=\"utf-8\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9635d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "preload_org.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79bf457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the columns to select for preload\n",
    "\n",
    "filter_preload_col = [\n",
    "        'PERNR', 'BEGDA', 'ENDDA', 'SEQNR', \n",
    "        'MASSN', 'MASSG', 'STAT2','PA0001.PERNR',\n",
    "        'PA0001.BEGDA', 'PA0001.ENDDA', 'PA0001.BUKRS', 'TOBE_WERKS',\n",
    "        'TOBE_BTRTL', 'TOBE_KOSTL', 'PA0001.GSBER', 'TOBE_PERSG',\n",
    "        'TOBE_ABKRS','TOBE_PERSK', 'PA0001.ANSVH', 'PA0001.PROZT',\n",
    "        'TOBE_PLANS','PA0001.STELL', 'TOBE_ORGEH', 'PA0001.SBMOD',\n",
    "        'PA0001.TOBE_SACHP','PA0001.SACHZ', 'PA0001.SACHA', 'PA0001.MSTBR'\n",
    "]\n",
    "\n",
    "# filter_preload_col = preload_org.columns\n",
    "\n",
    "# copy original preload DataFrame\n",
    "preload = preload_org.copy()\n",
    "\n",
    "# select only the relevant columns\n",
    "preload = preload[filter_preload_col]\n",
    "\n",
    "# adding prefix to column names\n",
    "preload.columns = org_col\n",
    "preload = preload.add_prefix('preload_')\n",
    "\n",
    "# strip whitespace from all object columns\n",
    "preload = preload.applymap(lambda x: x.strip() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df168b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_col.str.replace(r'\\d_', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8db7c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full join the preload and postload DataFrames\n",
    "reconcile = pd.merge(\n",
    "    preload, postload, \n",
    "    left_on=['preload_0_PERNR', 'preload_0_BEGDA', 'preload_0_ENDDA', 'preload_0_MASSN', 'preload_0_MASSG', 'preload_1_BEGDA', 'preload_1_ENDDA'], \n",
    "    right_on=['postload_0_PERNR', 'postload_0_BEGDA', 'postload_0_ENDDA', 'postload_0_MASSN', 'postload_0_MASSG', 'postload_1_BEGDA', 'postload_1_ENDDA'],\n",
    "    how='outer'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bbaed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconcile['preload_1_SBMOD'] = reconcile['preload_1_WERKS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641ee499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the first few rows of the reconcile DataFrame \n",
    "reconcile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0934306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reconcile), len(preload), len(postload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be298c98",
   "metadata": {},
   "source": [
    "# Split Reconcile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a011e566",
   "metadata": {},
   "source": [
    "## PA-0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6beafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_col_0_split = [\n",
    "    'preload_0_PERNR', 'preload_0_BEGDA', 'preload_0_ENDDA',\n",
    "    'preload_0_SEQNR', 'preload_0_MASSN', 'preload_0_MASSG',\n",
    "    'preload_0_STAT2'\n",
    "]\n",
    "\n",
    "post_col_0_split = [\n",
    "    'postload_0_PERNR', 'postload_0_BEGDA', 'postload_0_ENDDA',\n",
    "    'postload_0_SEQNR', 'postload_0_MASSN', 'postload_0_MASSG',\n",
    "    'postload_0_STAT2'\n",
    "]\n",
    "\n",
    "\n",
    "# select only from 0 columns\n",
    "preload_0_split = preload[pre_col_0_split]\n",
    "postload_0_split = postload[post_col_0_split]\n",
    "\n",
    "# full join the preload_0 and postload_0 DataFrames\n",
    "reconcile_0_split = pd.merge(\n",
    "    preload_0_split, postload_0_split, \n",
    "    left_on=['preload_0_PERNR', 'preload_0_BEGDA', 'preload_0_ENDDA', 'preload_0_MASSN', 'preload_0_MASSG'], \n",
    "    right_on=['postload_0_PERNR', 'postload_0_BEGDA', 'postload_0_ENDDA', 'postload_0_MASSN', 'postload_0_MASSG'],\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "reconcile_0_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a198d91f",
   "metadata": {},
   "source": [
    "## PA-0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c2094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_col_1_split = [\n",
    "    'preload_1_PERNR', 'preload_1_BEGDA',\n",
    "    'preload_1_ENDDA', 'preload_1_BUKRS', 'preload_1_WERKS',\n",
    "    'preload_1_BTRTL', 'preload_1_KOSTL', 'preload_1_GSBER',\n",
    "    'preload_1_PERSG', 'preload_1_ABKRS', 'preload_1_PERSK',\n",
    "    'preload_1_ANSVH', 'preload_1_PROZT', 'preload_1_PLANS',\n",
    "    'preload_1_STELL', 'preload_1_ORGEH', 'preload_1_SBMOD',\n",
    "    'preload_1_SACHP', 'preload_1_SACHZ', 'preload_1_SACHA',\n",
    "    'preload_1_MSTBR'\n",
    "]\n",
    "\n",
    "\n",
    "post_col_1_split = [\n",
    "    'postload_1_PERNR', 'postload_1_BEGDA',\n",
    "    'postload_1_ENDDA', 'postload_1_BUKRS', 'postload_1_WERKS',\n",
    "    'postload_1_BTRTL', 'postload_1_KOSTL', 'postload_1_GSBER',\n",
    "    'postload_1_PERSG', 'postload_1_ABKRS', 'postload_1_PERSK',\n",
    "    'postload_1_ANSVH', 'postload_1_PROZT', 'postload_1_PLANS',\n",
    "    'postload_1_STELL', 'postload_1_ORGEH', 'postload_1_SBMOD',\n",
    "    'postload_1_SACHP', 'postload_1_SACHZ', 'postload_1_SACHA',\n",
    "    'postload_1_MSTBR'\n",
    "]\n",
    "\n",
    "# select only from 1 columns\n",
    "preload_1_split = preload[pre_col_1_split]\n",
    "postload_1_split = postload[post_col_1_split]\n",
    "\n",
    "# full join the preload_1 and postload_1 DataFrames\n",
    "reconcile_1_split = pd.merge(\n",
    "    preload_1_split, postload_1_split, \n",
    "    left_on=['preload_1_PERNR', 'preload_1_BEGDA'], \n",
    "    right_on=['postload_1_PERNR', 'postload_1_BEGDA'],\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "reconcile_1_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3a2569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## save the reconcile DataFrame to an Excel file\n",
    "# ## เปลี่ยนตรงนี้\n",
    "result_path = r\"C:\\Users\\wasurat.boonnan\\OneDrive - Accenture\\Desktop\\Data Trnasfomation\\Transformed Data\\Mock4 Cut Over\\M4 Reconcile\\0000-0001\\Recocile_0000.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(path=result_path, engine='openpyxl') as writer:\n",
    "    reconcile.to_excel(writer, sheet_name='Reconcile_PA-0000', index=False)\n",
    "    reconcile_0_split.to_excel(writer, sheet_name='Reconcile_PA-0000_Split', index=False)\n",
    "    reconcile_1_split.to_excel(writer, sheet_name='Reconcile_PA-0001_Split', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
